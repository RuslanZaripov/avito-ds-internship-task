{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426850c4",
   "metadata": {},
   "source": [
    "# Тренировка модели машинного обучения\n",
    "\n",
    "Запускал ноутбук удаленно на Kaggle Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2e23d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 21 17:57:23 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5acfc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2d0d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    LogitsProcessor,\n",
    "    LogitsProcessorList,\n",
    ")\n",
    "import getpass\n",
    "os.environ[\"HF_TOKEN\"] =  getpass.getpass(\"Enter your HF_TOKEN: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65ab72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 64\n",
    "stride = 48\n",
    "seed = 2025\n",
    "val_size = 0.2\n",
    "max_examples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e57f77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdad757",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c6a4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_with_spaces(text):\n",
    "    method_choice = random.random()\n",
    "    \n",
    "    if method_choice < 0.1: # 10% - Remove all spaces\n",
    "        return text.replace(\" \", \"\")\n",
    "    \n",
    "    elif method_choice < 0.2: # 10% - Add space between each character\n",
    "        return \" \".join(text)\n",
    "    \n",
    "    else:\n",
    "        result_chars = []\n",
    "        \n",
    "        i = 0\n",
    "        n = len(text)\n",
    "    \n",
    "        while i < n:\n",
    "            current_char = text[i]\n",
    "            if current_char == ' ':\n",
    "                # It's a space. 20% chance to delete it (skip it).\n",
    "                if random.random() < 0.2:\n",
    "                    i += 1  # Just move to the next char, don't add this space.\n",
    "                    continue\n",
    "                else:\n",
    "                    result_chars.append(current_char)  # Keep the space.\n",
    "                    i += 1\n",
    "            else:\n",
    "                # It's a non-space character. Always add it.\n",
    "                result_chars.append(current_char)\n",
    "                # Check if there is a next character and it's also non-space\n",
    "                if i + 1 < n and text[i+1] != ' ':\n",
    "                    # 10% chance to insert an extra space after this character.\n",
    "                    if random.random() < 0.1:\n",
    "                        result_chars.append(' ')\n",
    "                i += 1\n",
    "\n",
    "    return ''.join(result_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ee60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filepath = '/kaggle/input/avito-ds-dataset/training_data_russian_literature.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e228be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_data_filepath, 'r') as file:\n",
    "    text = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b65679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0878b1fef44e4b8eb11dde2ebf85ad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/768526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_windows = []\n",
    "tgt_windows = []\n",
    "\n",
    "for i in tqdm(range(0, len(text), stride)):\n",
    "    src_window = text[i:i+window_length].strip()\n",
    "    # Generate the corrupted version of that window\n",
    "    tgt_window = process_text_with_spaces(src_window).strip()\n",
    "    \n",
    "    if len(src_window) > 0 and len(tgt_window) > 0:\n",
    "        src_windows.append(tgt_window)\n",
    "        tgt_windows.append(src_window)\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"src_text\": src_windows,\n",
    "    \"tgt_text\": tgt_windows,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdddd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src='ви и подпа пертью; ну, э то кусается .В тр ет ьем ра зряд е за э тотр'\n",
      "tgt='ви и под папертью; ну, это кусается. В третьем разряде за этот р'\n"
     ]
    }
   ],
   "source": [
    "idx = 105\n",
    "print(f\"src='{dataset['src_text'][idx]}'\")\n",
    "print(f\"tgt='{dataset['tgt_text'][idx]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865ce28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['src_text', 'tgt_text'],\n",
       "    num_rows: 768526\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c69d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['src_text', 'tgt_text'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "sample_size = min(dataset_size, max_examples)\n",
    "random_indices = random.sample(range(dataset_size), sample_size)\n",
    "dataset_limited = dataset.select(random_indices)\n",
    "dataset_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d1f5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = dataset_limited.train_test_split(test_size=val_size, seed=seed)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "val_dataset = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084aeb6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62722af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a8d8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zarus03/byt5-wsc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71a0452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(384, 1472)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1472)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(384, 1472)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-3): 3 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=1472, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=1472, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n",
       "              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1472, out_features=384, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b54e57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c0f58d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '</s>': 1,\n",
       " '<unk>': 2,\n",
       " '\\x00': 3,\n",
       " '\\x01': 4,\n",
       " '\\x02': 5,\n",
       " '\\x03': 6,\n",
       " '\\x04': 7,\n",
       " '\\x05': 8,\n",
       " '\\x06': 9,\n",
       " '\\x07': 10,\n",
       " '\\x08': 11,\n",
       " '\\t': 12,\n",
       " '\\n': 13,\n",
       " '\\x0b': 14,\n",
       " '\\x0c': 15,\n",
       " '\\r': 16,\n",
       " '\\x0e': 17,\n",
       " '\\x0f': 18,\n",
       " '\\x10': 19,\n",
       " '\\x11': 20,\n",
       " '\\x12': 21,\n",
       " '\\x13': 22,\n",
       " '\\x14': 23,\n",
       " '\\x15': 24,\n",
       " '\\x16': 25,\n",
       " '\\x17': 26,\n",
       " '\\x18': 27,\n",
       " '\\x19': 28,\n",
       " '\\x1a': 29,\n",
       " '\\x1b': 30,\n",
       " '\\x1c': 31,\n",
       " '\\x1d': 32,\n",
       " '\\x1e': 33,\n",
       " '\\x1f': 34,\n",
       " ' ': 35,\n",
       " '!': 36,\n",
       " '\"': 37,\n",
       " '#': 38,\n",
       " '$': 39,\n",
       " '%': 40,\n",
       " '&': 41,\n",
       " \"'\": 42,\n",
       " '(': 43,\n",
       " ')': 44,\n",
       " '*': 45,\n",
       " '+': 46,\n",
       " ',': 47,\n",
       " '-': 48,\n",
       " '.': 49,\n",
       " '/': 50,\n",
       " '0': 51,\n",
       " '1': 52,\n",
       " '2': 53,\n",
       " '3': 54,\n",
       " '4': 55,\n",
       " '5': 56,\n",
       " '6': 57,\n",
       " '7': 58,\n",
       " '8': 59,\n",
       " '9': 60,\n",
       " ':': 61,\n",
       " ';': 62,\n",
       " '<': 63,\n",
       " '=': 64,\n",
       " '>': 65,\n",
       " '?': 66,\n",
       " '@': 67,\n",
       " 'A': 68,\n",
       " 'B': 69,\n",
       " 'C': 70,\n",
       " 'D': 71,\n",
       " 'E': 72,\n",
       " 'F': 73,\n",
       " 'G': 74,\n",
       " 'H': 75,\n",
       " 'I': 76,\n",
       " 'J': 77,\n",
       " 'K': 78,\n",
       " 'L': 79,\n",
       " 'M': 80,\n",
       " 'N': 81,\n",
       " 'O': 82,\n",
       " 'P': 83,\n",
       " 'Q': 84,\n",
       " 'R': 85,\n",
       " 'S': 86,\n",
       " 'T': 87,\n",
       " 'U': 88,\n",
       " 'V': 89,\n",
       " 'W': 90,\n",
       " 'X': 91,\n",
       " 'Y': 92,\n",
       " 'Z': 93,\n",
       " '[': 94,\n",
       " '\\\\': 95,\n",
       " ']': 96,\n",
       " '^': 97,\n",
       " '_': 98,\n",
       " '`': 99,\n",
       " 'a': 100,\n",
       " 'b': 101,\n",
       " 'c': 102,\n",
       " 'd': 103,\n",
       " 'e': 104,\n",
       " 'f': 105,\n",
       " 'g': 106,\n",
       " 'h': 107,\n",
       " 'i': 108,\n",
       " 'j': 109,\n",
       " 'k': 110,\n",
       " 'l': 111,\n",
       " 'm': 112,\n",
       " 'n': 113,\n",
       " 'o': 114,\n",
       " 'p': 115,\n",
       " 'q': 116,\n",
       " 'r': 117,\n",
       " 's': 118,\n",
       " 't': 119,\n",
       " 'u': 120,\n",
       " 'v': 121,\n",
       " 'w': 122,\n",
       " 'x': 123,\n",
       " 'y': 124,\n",
       " 'z': 125,\n",
       " '{': 126,\n",
       " '|': 127,\n",
       " '}': 128,\n",
       " '~': 129,\n",
       " '\\x7f': 130,\n",
       " '\\x80': 131,\n",
       " '\\x81': 132,\n",
       " '\\x82': 133,\n",
       " '\\x83': 134,\n",
       " '\\x84': 135,\n",
       " '\\x85': 136,\n",
       " '\\x86': 137,\n",
       " '\\x87': 138,\n",
       " '\\x88': 139,\n",
       " '\\x89': 140,\n",
       " '\\x8a': 141,\n",
       " '\\x8b': 142,\n",
       " '\\x8c': 143,\n",
       " '\\x8d': 144,\n",
       " '\\x8e': 145,\n",
       " '\\x8f': 146,\n",
       " '\\x90': 147,\n",
       " '\\x91': 148,\n",
       " '\\x92': 149,\n",
       " '\\x93': 150,\n",
       " '\\x94': 151,\n",
       " '\\x95': 152,\n",
       " '\\x96': 153,\n",
       " '\\x97': 154,\n",
       " '\\x98': 155,\n",
       " '\\x99': 156,\n",
       " '\\x9a': 157,\n",
       " '\\x9b': 158,\n",
       " '\\x9c': 159,\n",
       " '\\x9d': 160,\n",
       " '\\x9e': 161,\n",
       " '\\x9f': 162,\n",
       " '\\xa0': 163,\n",
       " '¡': 164,\n",
       " '¢': 165,\n",
       " '£': 166,\n",
       " '¤': 167,\n",
       " '¥': 168,\n",
       " '¦': 169,\n",
       " '§': 170,\n",
       " '¨': 171,\n",
       " '©': 172,\n",
       " 'ª': 173,\n",
       " '«': 174,\n",
       " '¬': 175,\n",
       " '\\xad': 176,\n",
       " '®': 177,\n",
       " '¯': 178,\n",
       " '°': 179,\n",
       " '±': 180,\n",
       " '²': 181,\n",
       " '³': 182,\n",
       " '´': 183,\n",
       " 'µ': 184,\n",
       " '¶': 185,\n",
       " '·': 186,\n",
       " '¸': 187,\n",
       " '¹': 188,\n",
       " 'º': 189,\n",
       " '»': 190,\n",
       " '¼': 191,\n",
       " '½': 192,\n",
       " '¾': 193,\n",
       " '¿': 194,\n",
       " 'À': 195,\n",
       " 'Á': 196,\n",
       " 'Â': 197,\n",
       " 'Ã': 198,\n",
       " 'Ä': 199,\n",
       " 'Å': 200,\n",
       " 'Æ': 201,\n",
       " 'Ç': 202,\n",
       " 'È': 203,\n",
       " 'É': 204,\n",
       " 'Ê': 205,\n",
       " 'Ë': 206,\n",
       " 'Ì': 207,\n",
       " 'Í': 208,\n",
       " 'Î': 209,\n",
       " 'Ï': 210,\n",
       " 'Ð': 211,\n",
       " 'Ñ': 212,\n",
       " 'Ò': 213,\n",
       " 'Ó': 214,\n",
       " 'Ô': 215,\n",
       " 'Õ': 216,\n",
       " 'Ö': 217,\n",
       " '×': 218,\n",
       " 'Ø': 219,\n",
       " 'Ù': 220,\n",
       " 'Ú': 221,\n",
       " 'Û': 222,\n",
       " 'Ü': 223,\n",
       " 'Ý': 224,\n",
       " 'Þ': 225,\n",
       " 'ß': 226,\n",
       " 'à': 227,\n",
       " 'á': 228,\n",
       " 'â': 229,\n",
       " 'ã': 230,\n",
       " 'ä': 231,\n",
       " 'å': 232,\n",
       " 'æ': 233,\n",
       " 'ç': 234,\n",
       " 'è': 235,\n",
       " 'é': 236,\n",
       " 'ê': 237,\n",
       " 'ë': 238,\n",
       " 'ì': 239,\n",
       " 'í': 240,\n",
       " 'î': 241,\n",
       " 'ï': 242,\n",
       " 'ð': 243,\n",
       " 'ñ': 244,\n",
       " 'ò': 245,\n",
       " 'ó': 246,\n",
       " 'ô': 247,\n",
       " 'õ': 248,\n",
       " 'ö': 249,\n",
       " '÷': 250,\n",
       " 'ø': 251,\n",
       " 'ù': 252,\n",
       " 'ú': 253,\n",
       " 'û': 254,\n",
       " 'ü': 255,\n",
       " 'ý': 256,\n",
       " 'þ': 257,\n",
       " 'ÿ': 258,\n",
       " '<extra_id_0>': 259,\n",
       " '<extra_id_1>': 260,\n",
       " '<extra_id_2>': 261,\n",
       " '<extra_id_3>': 262,\n",
       " '<extra_id_4>': 263,\n",
       " '<extra_id_5>': 264,\n",
       " '<extra_id_6>': 265,\n",
       " '<extra_id_7>': 266,\n",
       " '<extra_id_8>': 267,\n",
       " '<extra_id_9>': 268,\n",
       " '<extra_id_10>': 269,\n",
       " '<extra_id_11>': 270,\n",
       " '<extra_id_12>': 271,\n",
       " '<extra_id_13>': 272,\n",
       " '<extra_id_14>': 273,\n",
       " '<extra_id_15>': 274,\n",
       " '<extra_id_16>': 275,\n",
       " '<extra_id_17>': 276,\n",
       " '<extra_id_18>': 277,\n",
       " '<extra_id_19>': 278,\n",
       " '<extra_id_20>': 279,\n",
       " '<extra_id_21>': 280,\n",
       " '<extra_id_22>': 281,\n",
       " '<extra_id_23>': 282,\n",
       " '<extra_id_24>': 283,\n",
       " '<extra_id_25>': 284,\n",
       " '<extra_id_26>': 285,\n",
       " '<extra_id_27>': 286,\n",
       " '<extra_id_28>': 287,\n",
       " '<extra_id_29>': 288,\n",
       " '<extra_id_30>': 289,\n",
       " '<extra_id_31>': 290,\n",
       " '<extra_id_32>': 291,\n",
       " '<extra_id_33>': 292,\n",
       " '<extra_id_34>': 293,\n",
       " '<extra_id_35>': 294,\n",
       " '<extra_id_36>': 295,\n",
       " '<extra_id_37>': 296,\n",
       " '<extra_id_38>': 297,\n",
       " '<extra_id_39>': 298,\n",
       " '<extra_id_40>': 299,\n",
       " '<extra_id_41>': 300,\n",
       " '<extra_id_42>': 301,\n",
       " '<extra_id_43>': 302,\n",
       " '<extra_id_44>': 303,\n",
       " '<extra_id_45>': 304,\n",
       " '<extra_id_46>': 305,\n",
       " '<extra_id_47>': 306,\n",
       " '<extra_id_48>': 307,\n",
       " '<extra_id_49>': 308,\n",
       " '<extra_id_50>': 309,\n",
       " '<extra_id_51>': 310,\n",
       " '<extra_id_52>': 311,\n",
       " '<extra_id_53>': 312,\n",
       " '<extra_id_54>': 313,\n",
       " '<extra_id_55>': 314,\n",
       " '<extra_id_56>': 315,\n",
       " '<extra_id_57>': 316,\n",
       " '<extra_id_58>': 317,\n",
       " '<extra_id_59>': 318,\n",
       " '<extra_id_60>': 319,\n",
       " '<extra_id_61>': 320,\n",
       " '<extra_id_62>': 321,\n",
       " '<extra_id_63>': 322,\n",
       " '<extra_id_64>': 323,\n",
       " '<extra_id_65>': 324,\n",
       " '<extra_id_66>': 325,\n",
       " '<extra_id_67>': 326,\n",
       " '<extra_id_68>': 327,\n",
       " '<extra_id_69>': 328,\n",
       " '<extra_id_70>': 329,\n",
       " '<extra_id_71>': 330,\n",
       " '<extra_id_72>': 331,\n",
       " '<extra_id_73>': 332,\n",
       " '<extra_id_74>': 333,\n",
       " '<extra_id_75>': 334,\n",
       " '<extra_id_76>': 335,\n",
       " '<extra_id_77>': 336,\n",
       " '<extra_id_78>': 337,\n",
       " '<extra_id_79>': 338,\n",
       " '<extra_id_80>': 339,\n",
       " '<extra_id_81>': 340,\n",
       " '<extra_id_82>': 341,\n",
       " '<extra_id_83>': 342,\n",
       " '<extra_id_84>': 343,\n",
       " '<extra_id_85>': 344,\n",
       " '<extra_id_86>': 345,\n",
       " '<extra_id_87>': 346,\n",
       " '<extra_id_88>': 347,\n",
       " '<extra_id_89>': 348,\n",
       " '<extra_id_90>': 349,\n",
       " '<extra_id_91>': 350,\n",
       " '<extra_id_92>': 351,\n",
       " '<extra_id_93>': 352,\n",
       " '<extra_id_94>': 353,\n",
       " '<extra_id_95>': 354,\n",
       " '<extra_id_96>': 355,\n",
       " '<extra_id_97>': 356,\n",
       " '<extra_id_98>': 357,\n",
       " '<extra_id_99>': 358,\n",
       " '<extra_id_100>': 359,\n",
       " '<extra_id_101>': 360,\n",
       " '<extra_id_102>': 361,\n",
       " '<extra_id_103>': 362,\n",
       " '<extra_id_104>': 363,\n",
       " '<extra_id_105>': 364,\n",
       " '<extra_id_106>': 365,\n",
       " '<extra_id_107>': 366,\n",
       " '<extra_id_108>': 367,\n",
       " '<extra_id_109>': 368,\n",
       " '<extra_id_110>': 369,\n",
       " '<extra_id_111>': 370,\n",
       " '<extra_id_112>': 371,\n",
       " '<extra_id_113>': 372,\n",
       " '<extra_id_114>': 373,\n",
       " '<extra_id_115>': 374,\n",
       " '<extra_id_116>': 375,\n",
       " '<extra_id_117>': 376,\n",
       " '<extra_id_118>': 377,\n",
       " '<extra_id_119>': 378,\n",
       " '<extra_id_120>': 379,\n",
       " '<extra_id_121>': 380,\n",
       " '<extra_id_122>': 381,\n",
       " '<extra_id_123>': 382,\n",
       " '<extra_id_124>': 383}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa73f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(custom_str)=6\n",
      "len(tokenized_seq)=13\n",
      "[211, 194, 212, 131, 211, 187, 211, 181, 211, 184, 212, 133, 1]\n"
     ]
    }
   ],
   "source": [
    "custom_str = 'привет'\n",
    "print(f\"{len(custom_str)=}\")\n",
    "tokenized_seq = tokenizer.encode(custom_str)\n",
    "print(f\"{len(tokenized_seq)=}\")\n",
    "print(tokenized_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61029132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"src_text\"],\n",
    "        max_length=window_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = tokenizer(\n",
    "        batch[\"tgt_text\"],\n",
    "        max_length=window_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f25f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e577f02126044748d248a36140fa177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd229cd9fbf64fbca3d7b3ec86963d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    preprocess, batched=True, remove_columns=[\"src_text\", \"tgt_text\"])\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    preprocess, batched=True, remove_columns=[\"src_text\", \"tgt_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e95c9e",
   "metadata": {},
   "source": [
    "## Constrained decoding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac3ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Constrained decoding: custom LogitsProcessor\n",
    "# ---------------------------\n",
    "# We'll implement a LogitsProcessor that, for each batch element at each generation step,\n",
    "# allows only two token ids:\n",
    "#   - space_id\n",
    "#   - the id for the next byte of the encoder input sequence (ignoring encoder padding)\n",
    "# Implementation details:\n",
    "# - The processor is initialized with encoder_input_ids (unpadded list of bytes) for each batch item.\n",
    "# - At each call, given input_ids (generated tokens so far), we compute pos = number of generated tokens that matched encoder bytes in order.\n",
    "#   - Spaces do not advance pos. When pos reaches encoder length, generation stops (or only spaces allowed).\n",
    "# - Then we set logits for disallowed tokens to -inf.\n",
    "\n",
    "class EDConstrainedLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, encoder_inputs: List[List[int]], pad_token_id: int, space_token_id: int):\n",
    "        \"\"\"\n",
    "        encoder_inputs: list of lists (for each batch element) containing encoder input ids \n",
    "        (without special padding or with padding - we'll trim)\n",
    "        \"\"\"\n",
    "        self.encoder_inputs = [self._trim(inp, pad_token_id) for inp in encoder_inputs]\n",
    "        self.pad = pad_token_id\n",
    "        self.space_id = space_token_id\n",
    "\n",
    "    def _trim(self, arr, pad_id):\n",
    "        # remove trailing pad tokens if present\n",
    "        trimmed = [int(x) for x in arr if int(x) != pad_id]\n",
    "        return trimmed\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        input_ids: (batch_size, cur_len)\n",
    "        scores: (batch_size, vocab_size) (logits for next token)\n",
    "        Return masked scores.\n",
    "        \"\"\"\n",
    "        bs = input_ids.size(0)\n",
    "        vocab_size = scores.size(-1)\n",
    "        device = scores.device\n",
    "        big_neg = -1e9\n",
    "\n",
    "        masked = scores.clone()\n",
    "\n",
    "        for i in range(bs):\n",
    "            enc = self.encoder_inputs[i]\n",
    "            # compute pos: number of previous generated tokens that match enc in order\n",
    "            # Skip BOS if present (T5 generation may start with decoder_start_token_id) — we only look at tokens after the decoder start.\n",
    "            gen = input_ids[i].tolist()\n",
    "            # compute position in encoder: count how many times we consumed a source token\n",
    "            pos = 0\n",
    "            enc_idx = 0\n",
    "            # iterate generated tokens (skip initial special tokens like bos if any)\n",
    "            # We assume that whenever a generated token equals enc[enc_idx], it consumes that input byte (pos++)\n",
    "            for tok in gen:\n",
    "                if enc_idx < len(enc) and tok == enc[enc_idx]:\n",
    "                    enc_idx += 1\n",
    "            pos = enc_idx\n",
    "\n",
    "            allowed = set()\n",
    "            allowed.add(self.space_id)\n",
    "            if pos < len(enc):\n",
    "                allowed.add(enc[pos])\n",
    "\n",
    "            # if pos >= len(enc): optionally allow only spaces or EOS, but here we will allow only EOS and space. We'll allow EOS as well.\n",
    "            if pos >= len(enc):\n",
    "                # optionally allow eos (if defined), but we don't know eos here. We'll allow space only.\n",
    "                allowed = {self.space_id}\n",
    "            # mask others\n",
    "            mask = torch.full((vocab_size,), big_neg, device=device)\n",
    "            allowed_list = list(allowed)\n",
    "            mask[allowed_list] = 0.0\n",
    "            masked[i] = scores[i] + mask\n",
    "\n",
    "        return masked\n",
    "\n",
    "def build_logits_processor_for_batch(batch_input_ids, pad_token_id, space_token_id):\n",
    "    # batch_input_ids: torch tensor (batch, seq_len)\n",
    "    encoder_inputs = [row.tolist() for row in batch_input_ids]\n",
    "    ed = EDConstrainedLogitsProcessor(\n",
    "        encoder_inputs=encoder_inputs,\n",
    "        pad_token_id=pad_token_id,\n",
    "        space_token_id=space_token_id\n",
    "    )\n",
    "    return LogitsProcessorList([ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46de791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7) Custom generate wrapper for constrained decoding\n",
    "# ---------------------------\n",
    "def generate_constrained(batch, max_length):\n",
    "    \"\"\"\n",
    "    batch: dict with 'input_ids' and 'attention_mask' (tensors, batched)\n",
    "    Return: list of decoded strings\n",
    "    \"\"\"\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    space_id = tokenizer.encode(\" \", add_special_tokens=False)[0]\n",
    "\n",
    "    logits_processor = build_logits_processor_for_batch(\n",
    "        input_ids.detach().cpu(),\n",
    "        pad_token_id=pad_id,\n",
    "        space_token_id=space_id\n",
    "    )\n",
    "\n",
    "    generated = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        logits_processor=logits_processor,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=False,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "    return generated.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e196ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 8) Seq2SeqTrainer but override prediction_step to use constrained decoding at eval time\n",
    "# ---------------------------\n",
    "class ConstrainedSeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.max_length = kwargs.pop('max_length', None)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        We override to use constrained generation at prediction time.\n",
    "        \"\"\"\n",
    "        # For training or when not predicting with generate, fallback\n",
    "        if not self.args.predict_with_generate or prediction_loss_only:\n",
    "            return super().prediction_step(model, inputs, prediction_loss_only, ignore_keys)\n",
    "\n",
    "        # otherwise, compute loss and also produce constrained predictions\n",
    "        # move inputs to device\n",
    "        has_labels = \"labels\" in inputs\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = self.compute_loss(model, inputs, return_outputs=False)\n",
    "\n",
    "        generated_tokens = generate_constrained(inputs, self.max_length)\n",
    "\n",
    "        if generated_tokens.shape[-1] < self.max_length:\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, self.max_length)\n",
    "\n",
    "        if has_labels:\n",
    "            labels = inputs[\"labels\"]\n",
    "            if labels.shape[-1] < self.max_length:\n",
    "                labels = self._pad_tensors_to_max_len(labels, self.max_length)\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        return (loss, generated_tokens, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad447167",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dbfaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_indices(text: str):\n",
    "    \"\"\"Return indices of spaces in the text\"\"\"\n",
    "    return {i for i, ch in enumerate(text) if ch.isspace()}\n",
    "\n",
    "\n",
    "def calculate_exact_match_accuracy(preds: list, labels: list) -> float:\n",
    "    \"\"\"Calculate exact string match accuracy\"\"\"\n",
    "    correct = sum(p == l for p, l in zip(preds, labels))\n",
    "    return correct / len(preds)\n",
    "\n",
    "\n",
    "def calculate_f1_score(preds: list, labels: list) -> dict:\n",
    "    \"\"\"Calculate F1 score and related metrics for space prediction\"\"\"\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for pred, label in zip(preds, labels):\n",
    "        pred_spaces = get_space_indices(pred)\n",
    "        ref_spaces = get_space_indices(label)\n",
    "\n",
    "        tp = len(pred_spaces & ref_spaces)\n",
    "        fp = len(pred_spaces - ref_spaces)\n",
    "        fn = len(ref_spaces - pred_spaces)\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "    \n",
    "    return np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1s)\n",
    "\n",
    "    \n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    preds = preds[0]\n",
    "\n",
    "    # Convert logits to predicted token IDs\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "    # preds is already numpy array (batch_size, seq_len)\n",
    "    # decode predictions\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in labels with pad_token_id before decoding\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Exact string match accuracy\n",
    "    acc = calculate_exact_match_accuracy(preds, labels)\n",
    "    p, r, f1 = calculate_f1_score(preds, labels)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f6811",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3353995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60/1764225300.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `ConstrainedSeq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8051' max='25000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8051/25000 2:12:41 < 4:39:24, 1.01 it/s, Epoch 3.22/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.053305</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>0.950373</td>\n",
       "      <td>0.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.052680</td>\n",
       "      <td>0.565750</td>\n",
       "      <td>0.937550</td>\n",
       "      <td>0.942311</td>\n",
       "      <td>0.938080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.052775</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.943563</td>\n",
       "      <td>0.949325</td>\n",
       "      <td>0.944630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.054038</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.951381</td>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.953393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60/4228915834.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished. Saving model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m                     ):\n\u001b[1;32m   2562\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./byt5-ed\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=2000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=2000,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_accumulation_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = ConstrainedSeq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    max_length=window_length,\n",
    ")\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training finished. Saving model...\")\n",
    "trainer.save_model(training_args.output_dir)\n",
    "\n",
    "print(f\"Model saved {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90eef6",
   "metadata": {},
   "source": [
    "## Load checkpoint and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee983bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spaces(text: str) -> str:\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=window_length\n",
    "    ).to(device)\n",
    "    \n",
    "    return [tokenizer.decode(seq, skip_special_tokens=True).strip()\n",
    "            for seq in generate_constrained(inputs, window_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d921c7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5462b36895074c26821c2673108503cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf6a8c122a246c98102519b165fc330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/3.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d110994a6d54ffb9366b0a7034fc7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8fb70f9d64ce9b3006f855be06ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/797 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c864cb33d2f54174937aa70733099d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4ea2631c2f474085c22bd386f3d05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60/3707838150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"zarus03/byt5-wsc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"zarus03/byt5-wsc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b744a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'работа в Москве удаленно'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_spaces('работавМосквеудаленно')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7855c4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 text_no_spaces\n",
       "0   0                куплюайфон14про\n",
       "1   1             ищудомвПодмосковье\n",
       "2   2  сдаюквартирусмебельюитехникой\n",
       "3   3     новыйдивандоставканедорого\n",
       "4   4                отдамдаромкошку"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/avito-ds-dataset/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d684aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2894a6149b40a78e46edbf3d11bb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "correcting:   0%|          | 0/1005 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['text_with_spaces'] = [correct_spaces(text)[0] \n",
    "                            for text in tqdm(test['text_no_spaces'], desc='correcting')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8c73c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "      <th>text_with_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "      <td>куплю айфон 14 про</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "      <td>ищу дом в Подмосковье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "      <td>сдаю квартиру с мебелью и техникой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "      <td>новый диван доставка недорого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "      <td>отдам даром кошку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>работавМосквеудаленно</td>\n",
       "      <td>работа в Москве удаленно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>куплютелевизорPhilips</td>\n",
       "      <td>куплю телев изор Philips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ищугрузчиковдляпереезда</td>\n",
       "      <td>ищу грузчиков для переезда</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ремонтквартирподключ</td>\n",
       "      <td>ремонт квартир подключ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>куплюноутбукHP</td>\n",
       "      <td>куплюно утбук HP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ищуквартирууметро</td>\n",
       "      <td>ищу квартиру умет ро</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>новаямикроволновкаSamsung</td>\n",
       "      <td>новаями кроволновка Samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>срочнопродамвелосипед</td>\n",
       "      <td>срочно продам велосипед</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>куплюгитаруFender</td>\n",
       "      <td>куплюгитару Fender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ищурепетиторапобиологии</td>\n",
       "      <td>ищу репетитора побиологии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>сдаюгаражнадлительныйсрок</td>\n",
       "      <td>сдаю гараж надлительный срок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>куплюдиванбу</td>\n",
       "      <td>куплю диванбу</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ищумастерапоремонтухолодильников</td>\n",
       "      <td>ищу мастера по ремонту холодильни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>новыйшкафдоставкасегодня</td>\n",
       "      <td>новый шкаф доставка сегодня</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>куплюXboxOne</td>\n",
       "      <td>куплю Xbox One</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                    text_no_spaces                    text_with_spaces\n",
       "0    0                   куплюайфон14про                  куплю айфон 14 про\n",
       "1    1                ищудомвПодмосковье               ищу дом в Подмосковье\n",
       "2    2     сдаюквартирусмебельюитехникой  сдаю квартиру с мебелью и техникой\n",
       "3    3        новыйдивандоставканедорого       новый диван доставка недорого\n",
       "4    4                   отдамдаромкошку                   отдам даром кошку\n",
       "5    5             работавМосквеудаленно            работа в Москве удаленно\n",
       "6    6             куплютелевизорPhilips            куплю телев изор Philips\n",
       "7    7           ищугрузчиковдляпереезда          ищу грузчиков для переезда\n",
       "8    8              ремонтквартирподключ              ремонт квартир подключ\n",
       "9    9                    куплюноутбукHP                    куплюно утбук HP\n",
       "10  10                 ищуквартирууметро                ищу квартиру умет ро\n",
       "11  11         новаямикроволновкаSamsung         новаями кроволновка Samsung\n",
       "12  12             срочнопродамвелосипед             срочно продам велосипед\n",
       "13  13                 куплюгитаруFender                  куплюгитару Fender\n",
       "14  14           ищурепетиторапобиологии           ищу репетитора побиологии\n",
       "15  15         сдаюгаражнадлительныйсрок        сдаю гараж надлительный срок\n",
       "16  16                      куплюдиванбу                       куплю диванбу\n",
       "17  17  ищумастерапоремонтухолодильников   ищу мастера по ремонту холодильни\n",
       "18  18          новыйшкафдоставкасегодня         новый шкаф доставка сегодня\n",
       "19  19                      куплюXboxOne                      куплю Xbox One"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c56ea1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('/kaggle/working/pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0f284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
